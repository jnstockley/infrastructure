---
x-airflow-common: &airflow-common
  image: jnstockley/airflow:2025.08.29
  networks:
    - private
    - proxy
  env_file:
    - .env
  environment: &airflow-common-env
    AIRFLOW__API__BASE_URL: https://airflow.local.jstockley.com
    TZ: America/Chicago
    AIRFLOW__CORE__DEFAULT_TIMEZONE: America/Chicago
    AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: America/Chicago
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: http://airflow-api-server:8080/execution/
    AIRFLOW_VAR_ENV: prod
    REDIS_URI: redis://redis:6379/0
    AUTHENTIK_APP_NANE: airflow-internal
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
#    AIRFLOW_CONFIG: '/opt/airflow/config/airflow.cfg'
    AIRFLOW__LOG_RETENTION_DAYS: 7
    AIRFLOW__WEBSERVER__EXPOSE_HOSTNAME: true
  volumes:
    - ./logs:/opt/airflow/logs
#    - ./config:/opt/airflow/config
    - ./data:/opt/airflow/data

name: airflow
services:
  airflow-apiserver:
    container_name: airflow-api-server
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: api-server
    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/api/v2/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    labels:
      - traefik.enable=true
      - traefik.http.routers.airflow.entrypoints=websecure
      - traefik.http.routers.airflow.rule=Host(`airflow.local.jstockley.com`)
      - traefik.http.routers.airflow.tls=true
      - traefik.http.routers.airflow.tls.certresolver=production
      - traefik.http.routers.airflow.service=airflow
      - traefik.http.services.airflow.loadbalancer.server.port=8080
    <<: *airflow-common

  airflow-dag-processor:
    container_name: airflow-dag-processor
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: dag-processor
    restart: always
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type DagProcessorJob --hostname
            "$${HOSTNAME}"'
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    <<: *airflow-common

  airflow-init:
    container_name: airflow-init
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
    env_file:
      - .env
    command: version
    <<: *airflow-common

  airflow-log-groomer:
    container_name: airflow-log-groomer
    environment:
      <<: *airflow-common-env
    command:
      - bash
      - /clean-logs
    <<: *airflow-common

  airflow-scheduler:
    container_name: airflow-scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: scheduler
    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    <<: *airflow-common

  airflow-triggerer:
    container_name: airflow-triggerer
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: triggerer
    restart: always
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type TriggererJob --hostname
            "$${HOSTNAME}"'
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    <<: *airflow-common

networks:
  proxy:
    name: proxy
    external: true
  private:
    name: private
    internal: true
    external: true
